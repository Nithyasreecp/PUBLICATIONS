# PUBLICATIONS

**fine-Tuning BLIP for General Image Captioning with LLM-Based Correction
Authers: Nithyasree cp, MR Harigopal;
Presented at 2025 IEEE 4th International Conference for Advancement in Technology (ICONAT)**

Image captioning is one of the most important computer vision problems with diverse applications from enhanced accessibility for the visually impaired to automated content generation for news media. Recent developments have focused on leveraging pre-trained models like BLIP (Bootstrapped Language-Image Pretraining) to generate textual captions for images. In this paper, we investigate fine-tuning BLIP for general image captioning and its limitations in contextual comprehension and linguistic accuracy. We introduce a new correction mechanism that leverages Large Language Models (LLMs) to rectify and enhance the generated captions. The proposed approach combines the best of both BLIP for vision-language grounding and LLMs for advanced natural language processing. Experimental results indicate drastic improvement in caption quality, paving the way to more robust and contextually compliant applications in automated content generation, image retrieval, and human-machine interaction
